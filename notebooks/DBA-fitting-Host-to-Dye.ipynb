{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321d39d7-082b-4594-83b0-4ceb68dad7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded boundaries:\n",
      "Id: [1.000e+03, 1.000e+18] M⁻¹\n",
      "I0: [0.000e+00, inf]\n",
      "Error loading file: [Errno 2] No such file or directory: '/Users/Frank/Downloads/DBA-fitting/merged_output-DBA.txt'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data loading failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 148\u001b[0m\n\u001b[1;32m    146\u001b[0m data_lines \u001b[38;5;241m=\u001b[39m load_data(file_path)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_lines \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData loading failed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    150\u001b[0m replicas \u001b[38;5;241m=\u001b[39m split_replicas(data_lines)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m replicas \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Data loading failed."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# File paths\n",
    "file_path = '/Users/Frank/Downloads/DBA-fitting/merged_output-DBA.txt'\n",
    "results_dir = os.path.dirname(file_path)\n",
    "results_file_path = os.path.join(results_dir, 'dye_alone_linear_fit_results.txt')\n",
    "\n",
    "# Input constants\n",
    "d0_in_M = 1.51e-6  # Total initial concentration of dye (M)\n",
    "\n",
    "#Fitting Thresholds\n",
    "rmse_threshold_factor = 2  # Factor to multiply the RSME for acceptable fits compared to the best fit.\n",
    "r2_threshold = 0.9    #R2 value used for filtering acceptable and unacceptable fits.\n",
    "\n",
    "#################################################################################################################\n",
    "# Do NOT change code after this line\n",
    "#################################################################################################################\n",
    "\n",
    "# Convert initial concentration to µM units\n",
    "d0 = d0_in_M * 1e6  # d0 in µM\n",
    "\n",
    "# Initialize parameter ranges with default boundaries\n",
    "I0_lower, I0_upper = 0, None\n",
    "Id_lower, Id_upper = 1e3 / 1e6, 1e18 / 1e6  # Convert Id range to µM⁻¹\n",
    "\n",
    "# Load prediction intervals for I0 and Id from existing results file if available\n",
    "if os.path.exists(results_file_path):\n",
    "    try:\n",
    "        with open(results_file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # Extract Id prediction interval from the file if available\n",
    "        id_prediction_line = next((line for line in lines if 'Id prediction interval' in line), None)\n",
    "        if id_prediction_line and 'not applicable' not in id_prediction_line:\n",
    "            Id_lower = float(id_prediction_line.split('[')[-1].split(',')[0].strip()) / 1e6\n",
    "            Id_upper = float(id_prediction_line.split(',')[-1].split(']')[0].strip()) / 1e6\n",
    "        else:\n",
    "            average_Id = float(next(line for line in lines if 'Average Id' in line).split('\\t')[-1].strip()) / 1e6\n",
    "            Id_lower, Id_upper = 0.5 * average_Id, 2.0 * average_Id\n",
    "\n",
    "        # Extract I0 prediction interval from the file if available\n",
    "        i0_prediction_line = next((line for line in lines if 'I0 prediction interval' in line), None)\n",
    "        if i0_prediction_line and 'not applicable' not in i0_prediction_line:\n",
    "            I0_lower = float(i0_prediction_line.split('[')[-1].split(',')[0].strip())\n",
    "            I0_upper = float(i0_prediction_line.split(',')[-1].split(']')[0].strip())\n",
    "        else:\n",
    "            average_I0 = float(next(line for line in lines if 'Average I0' in line).split('\\t')[-1].strip())\n",
    "            I0_lower, I0_upper = 0.5 * average_I0, 2.0 * average_I0\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing boundaries from the results file: {e}\")\n",
    "        Id_lower, Id_upper = 1e3 / 1e6, 1e18 / 1e6  # Default bounds if parsing fails\n",
    "        I0_lower, I0_upper = 0, np.inf\n",
    "else:\n",
    "    # Set default ranges if no results file is present\n",
    "    Id_lower, Id_upper = 1e3 / 1e6, 1e18 / 1e6\n",
    "    I0_lower, I0_upper = 0, np.inf\n",
    "\n",
    "# Print boundary values for verification\n",
    "print(f\"Loaded boundaries:\\nId: [{Id_lower * 1e6:.3e}, {Id_upper * 1e6:.3e}] M⁻¹\\nI0: [{I0_lower:.3e}, {I0_upper:.3e}]\")\n",
    "\n",
    "# Define function to calculate signal based on the parameters and h0 values\n",
    "def compute_signal(params, h0_values, d0):\n",
    "    I0, Kd, Id, Ihd = params\n",
    "    Signal_values = []\n",
    "    for h0 in h0_values:\n",
    "        delta = h0 - d0\n",
    "        a = Kd\n",
    "        b = Kd * delta + 1\n",
    "        c = -d0\n",
    "        discriminant = b**2 - 4 * a * c\n",
    "\n",
    "        if discriminant < 0:\n",
    "            Signal_values.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        sqrt_discriminant = np.sqrt(discriminant)\n",
    "        d1 = (-b + sqrt_discriminant) / (2 * a)\n",
    "        d2 = (-b - sqrt_discriminant) / (2 * a)\n",
    "\n",
    "        d = d1 if d1 >= 0 else d2 if d2 >= 0 else np.nan\n",
    "        if np.isnan(d):\n",
    "            Signal_values.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        h = d + delta\n",
    "        hd = Kd * h * d\n",
    "        Signal = I0 + Id * d + Ihd * hd\n",
    "        Signal_values.append(Signal)\n",
    "\n",
    "    return np.array(Signal_values)\n",
    "\n",
    "# Function to compute residuals between observed and computed signals\n",
    "def residuals(params, h0_values, Signal_observed, d0):\n",
    "    Signal_computed = compute_signal(params, h0_values, d0)\n",
    "    residual = Signal_observed - Signal_computed\n",
    "    residual = np.nan_to_num(residual, nan=1e6)\n",
    "    return residual\n",
    "\n",
    "# Function to calculate RMSE and R² for model evaluation\n",
    "def calculate_fit_metrics(Signal_observed, Signal_computed):\n",
    "    rmse = np.sqrt(np.nanmean((Signal_observed - Signal_computed) ** 2))\n",
    "    ss_res = np.nansum((Signal_observed - Signal_computed) ** 2)\n",
    "    ss_tot = np.nansum((Signal_observed - np.nanmean(Signal_observed)) ** 2)\n",
    "    r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else np.nan\n",
    "    return rmse, r_squared\n",
    "\n",
    "# Load data from the specified file path\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        return lines\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to split data into replicas based on specified delimiters\n",
    "def split_replicas(data):\n",
    "    replicas, current_replica = [], []\n",
    "    for line in data:\n",
    "        if \"var\" in line.lower():\n",
    "            if current_replica:\n",
    "                replicas.append(np.array(current_replica))\n",
    "                current_replica = []\n",
    "        else:\n",
    "            try:\n",
    "                x, y = map(float, line.split())\n",
    "                if x == 0.0 and current_replica:\n",
    "                    replicas.append(np.array(current_replica))\n",
    "                    current_replica = []\n",
    "                current_replica.append((x, y))\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    if current_replica:\n",
    "        replicas.append(np.array(current_replica))\n",
    "\n",
    "    return replicas if replicas else None\n",
    "\n",
    "# Load and process data, then split it into individual replicas\n",
    "data_lines = load_data(file_path)\n",
    "if data_lines is None:\n",
    "    raise ValueError(\"Data loading failed.\")\n",
    "\n",
    "replicas = split_replicas(data_lines)\n",
    "if replicas is None:\n",
    "    raise ValueError(\"Replica splitting failed.\")\n",
    "\n",
    "print(f\"Number of replicas detected: {len(replicas)}\")\n",
    "\n",
    "# Iterate through each replica to perform fitting and analysis\n",
    "for replica_index, replica_data in enumerate(replicas, start=1):\n",
    "    print(f\"Processing replica {replica_index}, data length: {len(replica_data)}\")\n",
    "    h0_values = replica_data[:, 0] * 1e6  # Convert h0 values to µM\n",
    "    Signal_observed = replica_data[:, 1]\n",
    "\n",
    "    # Skip replicas with insufficient data points\n",
    "    if len(h0_values) < 2:\n",
    "        print(f\"Replica {replica_index} has insufficient data. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Update I0_upper based on minimum observed signal if it was undefined\n",
    "    I0_upper = np.min(Signal_observed) if I0_upper is None or np.isinf(I0_upper) else I0_upper\n",
    "\n",
    "    # Generate initial parameter guesses within specified bounds\n",
    "    Ihd_guess_smaller = Signal_observed[0] < Signal_observed[-1]\n",
    "    initial_params_list = []\n",
    "    for _ in range(200):\n",
    "        I0_guess = np.random.uniform(I0_lower, I0_upper)\n",
    "        Kd_guess = 10 ** np.random.uniform(-5, 5)\n",
    "        if Ihd_guess_smaller:\n",
    "            Id_guess = 10 ** np.random.uniform(np.log10(Id_lower), np.log10(Id_upper))\n",
    "            Ihd_guess = Id_guess * np.random.uniform(0.1, 0.5)\n",
    "        else:\n",
    "            Ihd_guess = 10 ** np.random.uniform(np.log10(Id_lower), np.log10(Id_upper))\n",
    "            Id_guess = Ihd_guess * np.random.uniform(0.1, 0.5)\n",
    "        initial_params_list.append([I0_guess, Kd_guess, Id_guess, Ihd_guess])\n",
    "\n",
    "    # Perform optimization and collect results for each initial guess\n",
    "    best_result, best_cost = None, np.inf\n",
    "    fit_results = []\n",
    "    for initial_params in initial_params_list:\n",
    "        result = minimize(lambda params: np.sum(residuals(params, h0_values, Signal_observed, d0) ** 2),\n",
    "                          initial_params, method='L-BFGS-B',\n",
    "                          bounds=[(I0_lower, I0_upper), (1e-8, 1e8), (Id_lower, Id_upper), (1e-8, 1e8)])\n",
    "\n",
    "        Signal_computed = compute_signal(result.x, h0_values, d0)\n",
    "        rmse, r_squared = calculate_fit_metrics(Signal_observed, Signal_computed)\n",
    "        fit_results.append((result.x, result.fun, rmse, r_squared))\n",
    "\n",
    "        if result.fun < best_cost:\n",
    "            best_cost = result.fun\n",
    "            best_result = result\n",
    "\n",
    "    # Filter fit results based on RMSE and R² thresholds\n",
    "    best_rmse = min(fit_rmse for _, _, fit_rmse, _ in fit_results)\n",
    "    rmse_threshold = best_rmse * rmse_threshold_factor\n",
    "    #r2_threshold = 0.9\n",
    "\n",
    "    filtered_results = [\n",
    "        (params, fit_rmse, fit_r2) for params, _, fit_rmse, fit_r2 in fit_results\n",
    "        if fit_rmse <= rmse_threshold and fit_r2 >= r2_threshold\n",
    "    ]\n",
    "\n",
    "    # Calculate the median of the filtered parameters if they exist\n",
    "    if filtered_results:\n",
    "        median_params = np.median(np.array([result[0] for result in filtered_results]), axis=0)\n",
    "    else:\n",
    "        print(\"Warning: No fits meet the filtering criteria.\")\n",
    "        continue\n",
    "\n",
    "    # Compute signal and metrics for the median parameters\n",
    "    Signal_computed = compute_signal(median_params, h0_values, d0)\n",
    "    rmse, r_squared = calculate_fit_metrics(Signal_observed, Signal_computed)\n",
    "\n",
    "    # Generate points for the fitting curve to overlay on observed data\n",
    "    fitting_curve_x, fitting_curve_y = [], []\n",
    "    for i in range(len(h0_values) - 1):\n",
    "        extra_points = np.linspace(h0_values[i], h0_values[i + 1], 21)\n",
    "        fitting_curve_x.extend(extra_points)\n",
    "        fitting_curve_y.extend(compute_signal(median_params, extra_points, d0))\n",
    "\n",
    "    last_signal = compute_signal(median_params, [h0_values[-1]], d0)[0]\n",
    "    fitting_curve_x.append(h0_values[-1])\n",
    "    fitting_curve_y.append(last_signal)\n",
    "\n",
    "    # Plot observed vs. simulated fitting curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(h0_values, Signal_observed, 'o', label='Observed Signal')\n",
    "    plt.plot(fitting_curve_x, fitting_curve_y, '--', color='blue', alpha=0.6, label='Simulated Fitting Curve')\n",
    "    plt.xlabel('h0 (µM)')\n",
    "    plt.ylabel('Signal')\n",
    "    plt.title(f'Observed vs. Simulated Fitting Curve for Replica {replica_index}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    param_text = (f\"Kd: {median_params[1] * 1e6:.2e} M^-1\\n\"\n",
    "                  f\"I0: {median_params[0]:.2e}\\n\"\n",
    "                  f\"Id: {median_params[2] * 1e6:.2e} signal/M\\n\"\n",
    "                  f\"Ihd: {median_params[3] * 1e6:.2e} signal/M\\n\"\n",
    "                  f\"RMSE: {rmse:.3f}\\n\"\n",
    "                  f\"R²: {r_squared:.3f}\")\n",
    "\n",
    "    plt.gca().annotate(param_text, xy=(1.05, 0.5), xycoords='axes fraction', fontsize=10,\n",
    "                       bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"lightgrey\"))\n",
    "\n",
    "    plot_file = os.path.join(results_dir, f\"fit_plot_replica_{replica_index}.png\")\n",
    "    plt.savefig(plot_file, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate RMSE and R² for the median fit\n",
    "    median_rmse, median_r2 = calculate_fit_metrics(Signal_observed, Signal_computed)\n",
    "\n",
    "    # Export fit parameters and results to a text file\n",
    "    replica_file = os.path.join(results_dir, f\"fit_results_replica_{replica_index}.txt\")\n",
    "    with open(replica_file, 'w') as f:\n",
    "        f.write(f\"Input:\\nd0 (M): {d0_in_M:.6e}\\n\")\n",
    "        f.write(f\"Id lower bound: {Id_lower * 1e6:.3e} signal/M\\n\")\n",
    "        f.write(f\"Id upper bound: {Id_upper * 1e6:.3e} signal/M\\n\")\n",
    "        f.write(f\"I0 lower bound: {I0_lower:.3e}\\n\")\n",
    "        f.write(f\"I0 upper bound: {I0_upper:.3e}\\n\")\n",
    "\n",
    "        f.write(\"\\nOutput:\\nMedian parameters:\\n\")\n",
    "        f.write(f\"I0: {median_params[0]:.2e}\\n\")\n",
    "        f.write(f\"Kd: {median_params[1] * 1e6:.2e} M^-1\\n\")\n",
    "        f.write(f\"Id: {median_params[2] * 1e6:.2e} signal/M\\n\")\n",
    "        f.write(f\"Ihd: {median_params[3] * 1e6:.2e} signal/M\\n\")\n",
    "        f.write(f\"RMSE: {median_rmse:.3f}\\n\")\n",
    "        f.write(f\"R²: {median_r2:.3f}\\n\")\n",
    "\n",
    "        # Export only acceptable filtered fit parameters\n",
    "        f.write(\"\\nAcceptable Fit Parameters:\\n\")\n",
    "        f.write(\"Kd (M^-1)\\tI0\\tId (signal/M)\\tIhd (signal/M)\\tRMSE\\tR²\\n\")\n",
    "        for params, fit_rmse, fit_r2 in filtered_results:\n",
    "            f.write(f\"{params[1] * 1e6:.2e}\\t{params[0]:.2e}\\t{params[2] * 1e6:.2e}\\t{params[3] * 1e6:.2e}\\t{fit_rmse:.3f}\\t{fit_r2:.3f}\\n\")\n",
    "\n",
    "        # Write the standard deviations\n",
    "        f.write(\"\\nStandard Deviations:\\n\")\n",
    "        f.write(f\"Kd Std Dev: {Kd_std:.2e} M^-1\\n\")\n",
    "        f.write(f\"I0 Std Dev: {I0_std:.2e}\\n\")\n",
    "        f.write(f\"Id Std Dev: {Id_std:.2e} signal/M\\n\")\n",
    "        f.write(f\"Ihd Std Dev: {Ihd_std:.2e} signal/M\\n\")\n",
    "\n",
    "        # Write the input signal data\n",
    "        f.write(\"\\nOriginal Data:\\nConcentration (M)\\tSignal\\n\")\n",
    "        for h0, signal in zip(h0_values / 1e6, Signal_observed):  # Convert h0_values to M\n",
    "            f.write(f\"{h0:.6e}\\t{signal:.6e}\\n\")\n",
    "\n",
    "        # Write the fitting curve data\n",
    "        f.write(\"\\nFitting Curve:\\n\")\n",
    "        f.write(\"Simulated Concentration (M)\\tSimulated Signal\\n\")\n",
    "        for x_sim, y_sim in zip(np.array(fitting_curve_x) / 1e6, fitting_curve_y):  # Convert fitting_curve_x to M\n",
    "            f.write(f\"{x_sim:.6e}\\t{y_sim:.6e}\\n\")\n",
    "        f.write(f\"\\nDate of Export: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")   # Exports time stamp\n",
    "\n",
    "    print(f\"Results for Replica {replica_index} saved to {replica_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e01f037-205b-43e3-ba98-212a2688bb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066885ce-6711-4b3c-b67e-f3fba26de9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
